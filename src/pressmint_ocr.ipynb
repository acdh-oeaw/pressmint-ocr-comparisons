{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e991c29-01bc-4ee3-9a62-c304d0ecc635",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149a4dde-0b8f-4d79-a1ae-17da3b8add3d",
   "metadata": {},
   "source": [
    "## dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b711b5a9-805d-4782-ab14-7078033ff956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import difflib\n",
    "import getpass\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import anthropic\n",
    "import Levenshtein\n",
    "import openai\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import vertexai\n",
    "from google.cloud import vision\n",
    "from google.oauth2 import service_account\n",
    "from jiwer import cer, wer\n",
    "from PIL import Image\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf25a4c-3f2c-4ffe-9905-802aa20d5455",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53110faa-f080-4b76-9233-781219c2bf2e",
   "metadata": {},
   "source": [
    "## files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58be3deb-9831-41dc-a1a1-f9cb98f8401c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd6ba7-aba6-4f56-b04f-c9d1d0d0f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data/keys/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9604cb-445b-40aa-8b81-20fd97cc7a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data/texts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f20f5-9d1c-4541-9d6e-9d935b96cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data/texts/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594383e9-9c9f-4adb-a150-85fd8430611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/keys/tokens.json\", \"r\") as f:\n",
    "    tokens_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ee997-0432-4160-b5b6-82df6b259d19",
   "metadata": {},
   "source": [
    "## global vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26de39b7-841f-4c0f-8365-94fe0041b34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "images_folder = Path(\"/data/texts/images\")\n",
    "transkribus_inferenced_folder = Path(\"/data/texts/transkribus_inferenced\")\n",
    "transkribus_corrected_folder = Path(\"/data/texts/transkribus_corrected\")\n",
    "openai_simple_folder = Path(\"/data/texts/openai_simple\")\n",
    "openai_extensive_folder = Path(\"/data/texts/openai_extensive\")\n",
    "google_vision_folder = Path(\"/data/texts/google_vision\")\n",
    "google_gemini_simple_folder = Path(\"/data/texts/google_gemini_simple\")\n",
    "google_gemini_extensive_folder = Path(\"/data/texts/google_gemini_extensive\")\n",
    "anthropic_simple_folder = Path(\"/data/texts/anthropic_simple\")\n",
    "anthropic_extensive_folder = Path(\"/data/texts/anthropic_extensive\")\n",
    "plot_path = Path(\"/data/analysis/plot.png\")\n",
    "df_path = Path(\"/data/analysis/df.pkl\")\n",
    "\n",
    "# openai\n",
    "openai_client = openai.OpenAI(api_key=tokens_dict[\"openai_token\"])\n",
    "\n",
    "# google\n",
    "google_credentials = service_account.Credentials.from_service_account_file(\"/data/keys/google_key.json\")\n",
    "google_vision_client = vision.ImageAnnotatorClient(credentials=google_credentials)\n",
    "vertexai.init(project=\"project-pressmint-ocr\", location=\"us-central1\", credentials=google_credentials)\n",
    "google_model = GenerativeModel(\"gemini-2.5-flash-lite\")\n",
    "\n",
    "# anthropic\n",
    "anthropic_client = anthropic.Anthropic(api_key=tokens_dict[\"anthropic_token\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94aa5bd-3026-483a-9767-f4ee5e0ce278",
   "metadata": {},
   "source": [
    "# text comparison metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b651f2-5696-42f8-898c-0a2c4f159cf8",
   "metadata": {},
   "source": [
    "## diff_levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd63f3-27a3-4683-9b29-f89c57f6d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_levenshtein(text_a: str, text_b: str) -> float:\n",
    "    lev_dist = Levenshtein.distance(text_a, text_b)\n",
    "    lev_norm = lev_dist / max(len(text_a), len(text_b))\n",
    "    return lev_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47d1b6-80d7-47c4-a58e-fc14d70bb792",
   "metadata": {},
   "source": [
    "## diff_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f6b963-e113-4fcd-b562-0359a4829d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_wer(text_a: str, text_b: str) -> float:\n",
    "    return wer(text_a, text_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deefc1c1-e883-47fc-94dd-9f5bf63bc205",
   "metadata": {},
   "source": [
    "## diff_cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ba184-90a2-4b50-b013-9365eb6b69a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_cer(text_a: str, text_b: str) -> float:\n",
    "    return cer(text_a, text_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f0179-a9b2-4ada-991a-2af05c26b476",
   "metadata": {},
   "source": [
    "## diff_difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1728a91-72d1-4b14-b1fa-f5f222a2838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_difflib(text_a: str, text_b: str) -> float:\n",
    "    seq = difflib.SequenceMatcher(None, text_a, text_b)\n",
    "    return seq.ratio()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e863878-cf52-46b6-a2c8-dcb8cd3c2513",
   "metadata": {},
   "source": [
    "## diff_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a047191-ef6a-4972-a5b9-a49f998bd1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_all(text_a: str, text_b: str) -> float:\n",
    "    return {\n",
    "        \"diff_levenshtein\": diff_levenshtein(text_a, text_b),\n",
    "        \"diff_wer\": diff_wer(text_a, text_b),\n",
    "        \"diff_cer\": diff_cer(text_a, text_b),\n",
    "        \"diff_difflib\": diff_difflib(text_a, text_b),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a83371-4491-43bf-9c3f-11da499215f4",
   "metadata": {},
   "source": [
    "## tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bbdc0c-cddf-4146-8f88-29593eabd389",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_a = \"\"\"\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elit.\n",
    "Sed do eiusmod tempor incididunt ut labore et dolore.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bd08c0-a56a-4def-ae2f-977edac6d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letzte Wörter:\n",
    "# elat statt elit\n",
    "# dalare statt dolore\n",
    "text_b = \"\"\"\n",
    "Lorem ipsum dolor sit amet, consectetur adipiscing elat.\n",
    "Sed do eiusmod tempor incididunt ut labore et dalare.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61013cbe-cc4b-4a6c-a3b0-8b78994608a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o mit a\n",
    "# i mit e\n",
    "# d mit x\n",
    "text_c = \"\"\"\n",
    "Larem epsum xalar set amet, cansectetur axepesceng elet.\n",
    "Sex xa eeusmax tempar encexexunt ut labare et xalare.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb08ce9c-10be-4b78-a5e0-b185680fad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erster und zweiter Satz vertauscht\n",
    "text_d = \"\"\"\n",
    "Sed do eiusmod tempor incididunt at labore dolore.\n",
    "Lorem ipsum dolor sit amet consectetur adipiscing elit.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d588830-5f75-41f3-a0e8-7f2c53a870d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gänzlich neue Sätze\n",
    "text_e = \"\"\"\n",
    "Commodo nulla facilisi nullam vehicula ipsum a arcu.\n",
    "Pulvinar proin gravida hendrerit lectus.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79718b-eff4-4597-9091-1261cc7f29d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_all(text_a, text_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897c478-b1e1-42ad-bda0-7829082dc6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_all(text_a, text_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254be24b-b221-4c79-acc3-67903f821c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_all(text_a, text_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74200aa4-1bf6-4ea9-8268-f525fc1aef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_all(text_a, text_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9436d736-ffbd-4808-80e4-50af8ede654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_all(text_a, text_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ed1d5-9bf2-4f30-bc49-5daca9b86825",
   "metadata": {},
   "source": [
    "# reader functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2a3177-8cc5-4474-8855-33e27b1ee2eb",
   "metadata": {},
   "source": [
    "## get_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7871b0c-c0ed-4571-8847-c2202333fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(image_id: str) -> Path:\n",
    "    return images_folder / Path(image_id + \".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c81d8-79c1-4e88-a54b-2cae1eb62447",
   "metadata": {},
   "source": [
    "## read_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26c49e-fc5c-4861-88be-823b55b7c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(image_id: str) -> str:\n",
    "    with open(transkribus_corrected_folder / Path(image_id + \".txt\"), \"r\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0061d-ca10-4273-b22b-fdb7a0568092",
   "metadata": {},
   "source": [
    "## read_image_as_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fc925b-a50d-49b6-a96d-f7aaa4bf21e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_as_string(image_id: str) -> str:\n",
    "    with open(get_image_path(image_id), \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a11ec5-e843-4ca9-ad27-30d90553d17c",
   "metadata": {},
   "source": [
    "## read_image_as_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cae3ef-e862-4dd1-94f5-e409432bd383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_as_binary(image_id: str) -> bytes:\n",
    "    with open(get_image_path(image_id), \"rb\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffc10b7-8464-4ebb-b525-68512cee5778",
   "metadata": {},
   "source": [
    "## read_image_as_gemini_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38c5d1d-a595-4277-9e2a-0d8550db90b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_as_gemini_part(image_id: str) -> bytes:\n",
    "    img = Image.open(get_image_path(image_id))\n",
    "    img_byte_arr = io.BytesIO()\n",
    "    img.save(img_byte_arr, format=\"JPEG\")\n",
    "    img_byte_arr = img_byte_arr.getvalue()\n",
    "    image_part = Part.from_data(data=img_byte_arr, mime_type=\"image/jpeg\")\n",
    "    return image_part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384d61a3-7737-4f88-9f2b-65cd5eef3879",
   "metadata": {},
   "source": [
    "## get_image_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4779e-7bd4-4d3d-a190-0829d9af16e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_ids() -> list[str]:\n",
    "    image_id_list = []\n",
    "    for image_path in sorted(images_folder.iterdir()):\n",
    "        if \"test\" not in str(image_path):\n",
    "            image_id_list.append(image_path.stem)\n",
    "    return image_id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add86023-96c3-4120-8ed6-a0ce59468d26",
   "metadata": {},
   "source": [
    "## tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c509cd2-ee69-448e-9e82-224b541c1f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(read_image_as_string(\"test\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be634198-9afe-47a8-97e9-12b4a2823c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(read_image_as_binary(\"test\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c7618d-f651-42ab-9b36-9fdb9fe5d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_id in get_image_ids():\n",
    "    print(image_id)\n",
    "    print(len(read_image_as_string(image_id)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959cd748-374d-4960-bcbf-11585f13ff17",
   "metadata": {},
   "source": [
    "# OCR inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c090f-7cc1-456a-8038-ae7c0af879f2",
   "metadata": {},
   "source": [
    "## prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e660d3-7620-4819-afdc-95cc616d1474",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_simple = \"Extrahiere den Text aus diesem Bild.\"\n",
    "prompt_extensive = (\n",
    "    \"Das ist ein Scan einer deutschen historischen Zeitung aus dem frühen 20. Jahrhundert.\"\n",
    "    \"Bitte führe OCR darauf aus. \"\n",
    "    \"Beachte dabei, dass die Schrift in Fraktur gehalten ist. \"\n",
    "    \"Versuche keine Interpretationen zu machen bezüglich der Wörter, sondern transkripiere jeden Buchstaben wie du ihn siehst. \"\n",
    "    \"Ohne irgendwelche Metabeschreibungen, nur den Text alleine.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0533dc1c-09d4-45a0-84f6-3137cd975840",
   "metadata": {},
   "source": [
    "## ocr_transkribus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e4dda-dd67-4ecd-8b1c-90d423b39886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_transkribus(image_id: str) -> str:\n",
    "    with open(transkribus_inferenced_folder / Path(image_id + \".txt\"), \"r\") as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70900e64-7dfa-4d13-84b6-330475442719",
   "metadata": {},
   "source": [
    "## ocr_openai_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d558d-bc3a-4ea4-b11c-51f131b76098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_openai_base(prompt: str, image_id: str) -> str:\n",
    "    image = read_image_as_string(image_id)\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt,\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{image}\",\n",
    "                            \"detail\": \"high\",\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=2048,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc681f7e-36c4-4081-a830-a0eaa113fa90",
   "metadata": {},
   "source": [
    "## ocr_openai_prompt_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b6cb5e-8670-4734-8b4a-6a821bb8c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_openai_prompt_simple(image_id: str) -> str:\n",
    "    return ocr_openai_base(prompt_simple, image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c14ee6-ea7f-4c66-b031-272355526a32",
   "metadata": {},
   "source": [
    "## ocr_openai_prompt_extensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f955c787-e5e9-46aa-b252-7fc85f3f01b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_openai_prompt_extensive(image_id: str) -> str:\n",
    "    return ocr_openai_base(prompt_extensive, image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110ea2e-515e-4ea5-abf5-435a64035c2d",
   "metadata": {},
   "source": [
    "## ocr_openai_one_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed0de21-d19a-45dc-961c-a047cbbdcf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_openai_one_shot(image_id_ground_truth: str, image_id_inference: str) -> str:\n",
    "    image_ground_truth = read_image_as_string(image_id_ground_truth)\n",
    "    image_inference = read_image_as_string(image_id_inference)\n",
    "    text_ground_truth = read_text(image_id)\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Hier ist ein Beispielbild einer historischen Frakturschrift-Zeitung mit seiner korrekten Transkription:\",\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{image_ground_truth}\",\n",
    "                            \"detail\": \"high\",\n",
    "                        },\n",
    "                    },\n",
    "                    {\"type\": \"text\", \"text\": text_ground_truth},\n",
    "                    {\"type\": \"text\", \"text\": \"Bitte beschreibe das folgende ähnliche Bild, so gut wie möglich.\"},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{image_inference}\",\n",
    "                            \"detail\": \"high\",\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=2048,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba92da-32e8-4863-a3ac-2d3ee3dde421",
   "metadata": {},
   "source": [
    "## ocr_google_vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b59152-21a9-445c-ac23-dad7b1806034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_google_vision(image_id: str) -> str:\n",
    "    image = vision.Image(content=read_image_as_binary(image_id))\n",
    "    response = google_vision_client.document_text_detection(image=image)\n",
    "    document = response.full_text_annotation\n",
    "    return document.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee6ec3c-a79b-45fa-84e6-4ba7beabf47b",
   "metadata": {},
   "source": [
    "## ocr_google_gemini_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b23f59-5061-441c-8ace-edfd72b711c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_google_gemini_base(prompt: str, image_id: str) -> str:\n",
    "    image_part = read_image_as_gemini_part(image_id)\n",
    "    response = google_model.generate_content([prompt, image_part])\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef6c8dd-f338-45f7-9abc-fe3101039c90",
   "metadata": {},
   "source": [
    "## ocr_google_gemini_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b08aacf-e9a5-4f73-9cce-b8df899fee85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_google_gemini_simple(image_id: str) -> str:\n",
    "    return ocr_google_gemini_base(prompt_simple, image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6cc356-4501-42ba-ae4e-cb33e099f967",
   "metadata": {},
   "source": [
    "## ocr_google_gemini_extensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce424d5-6084-41b8-9c3b-778d254f1b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_google_gemini_extensive(image_id: str) -> str:\n",
    "    return ocr_google_gemini_base(prompt_extensive, image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd99700e-7c20-4c15-8126-96befb656acb",
   "metadata": {},
   "source": [
    "## ocr_anthropic_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8699dc5d-a0c2-4581-bec3-b7646b3af9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_anthropic_base(prompt: str, image_id: str) -> str:\n",
    "    image = read_image_as_string(image_id)\n",
    "    message = anthropic_client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=4000,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/jpeg\",\n",
    "                            \"data\": image,\n",
    "                        },\n",
    "                    },\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5048895-a9bc-4b74-8704-f2e4effbc01d",
   "metadata": {},
   "source": [
    "## ocr_anthropic_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01144217-3e2f-4b27-92dd-d233085253ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_anthropic_simple(image_id: str) -> str:\n",
    "    return ocr_anthropic_base(prompt_simple, image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f8ab98-1b58-4d78-9ade-a5151394d85d",
   "metadata": {},
   "source": [
    "## ocr_anthropic_extensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6e042-63bc-4146-bd23-548eaa496fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_anthropic_extensive(image_id: str) -> str:\n",
    "    return ocr_anthropic_base(prompt_extensive, image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb7225-df52-43b8-9896-bed64f6ed732",
   "metadata": {},
   "source": [
    "## get_all_ocr_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25786c0f-6289-4972-9133-9414d83b4e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_ocr_func() -> list[Callable]:\n",
    "    return [\n",
    "        ocr_transkribus,\n",
    "        ocr_openai_prompt_simple,\n",
    "        ocr_openai_prompt_extensive,\n",
    "        ocr_openai_one_shot,\n",
    "        ocr_google_vision,\n",
    "        ocr_google_gemini_simple,\n",
    "        ocr_google_gemini_extensive,\n",
    "        ocr_anthropic_simple,\n",
    "        ocr_anthropic_extensive,\n",
    "    ]\n",
    "    # return [ocr_transkribus, ocr_openai_prompt_simple, ocr_openai_prompt_extensive]\n",
    "    # return [ocr_transkribus, ocr_openai_one_shot]\n",
    "    # return [ocr_transkribus, ocr_anthropic_simple]\n",
    "    # return [ocr_transkribus]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae5b8c-b652-4685-8ece-58d9d30ebae0",
   "metadata": {},
   "source": [
    "## get_ocr_output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6537b9-8e7e-404e-a4ea-0cc177c291a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ocr_output_folder(ocr_func: Callable) -> str:\n",
    "    if ocr_func is ocr_transkribus:\n",
    "        return None\n",
    "    elif ocr_func is ocr_openai_prompt_simple:\n",
    "        return openai_simple_folder\n",
    "    elif ocr_func is ocr_openai_prompt_extensive:\n",
    "        return openai_extensive_folder\n",
    "    elif ocr_func is ocr_google_vision:\n",
    "        return google_vision_folder\n",
    "    elif ocr_func is ocr_google_gemini_simple:\n",
    "        return google_gemini_simple_folder\n",
    "    elif ocr_func is ocr_google_gemini_extensive:\n",
    "        return google_gemini_extensive_folder\n",
    "    elif ocr_func is ocr_anthropic_simple:\n",
    "        return anthropic_simple_folder\n",
    "    elif ocr_func is ocr_openai_prompt_extensive:\n",
    "        return anthropic_extensive_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0afb9d-2300-43a6-a048-68c11855805e",
   "metadata": {},
   "source": [
    "## tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a543fc1-eb5f-4c39-b740-539271a4f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ocr_func in get_all_ocr_func():\n",
    "#     print(\"\\n-----------------------------------------------------------------------\")\n",
    "#     print(ocr_func.__name__, \"\\n\")\n",
    "#     text = ocr_func(\"1915-12-28-1\", \"1915-12-28-2\")\n",
    "#     print(text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add5ab71-a134-4bcc-bcd7-5ec606215b29",
   "metadata": {},
   "source": [
    "# aggregated analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed6a6ea-cc9f-4229-83bb-f6235ac8e993",
   "metadata": {},
   "source": [
    "## compare all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f6b1c-f456-489a-a2ae-47a579bfedf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_name_list = [\"diff_levenshtein\", \"diff_wer\", \"diff_cer\", \"diff_difflib\"]\n",
    "diff_data_columns = [\"function\", \"image_id\"] + diff_name_list\n",
    "diff_data_all = []\n",
    "\n",
    "# iterate over functions\n",
    "for ocr_func in get_all_ocr_func():\n",
    "    print(f\"ocr_func: {ocr_func.__name__}\")\n",
    "\n",
    "    # prepare average data dict\n",
    "    diff_sum_dict = {diff_name: 0 for diff_name in diff_name_list}\n",
    "\n",
    "    # iterate over images\n",
    "    image_id_list = get_image_ids()\n",
    "    for image_id in image_id_list:\n",
    "        print(f\"image_id: {image_id}\")\n",
    "\n",
    "        # compare ground truth with inferenced text\n",
    "        text_ground_truth = read_text(image_id)\n",
    "        if ocr_func is ocr_openai_one_shot:\n",
    "            image_id_ground_truth = None\n",
    "            if image_id.endswith(\"1\"):\n",
    "                image_id_ground_truth = image_id = image_id[:-1] + \"2\"\n",
    "            elif image_id.endswith(\"2\"):\n",
    "                image_id_ground_truth = image_id = image_id[:-1] + \"1\"\n",
    "            elif image_id.endswith(\"3\"):\n",
    "                image_id_ground_truth = image_id = image_id[:-1] + \"4\"\n",
    "            elif image_id.endswith(\"4\"):\n",
    "                image_id_ground_truth = image_id = image_id[:-1] + \"3\"\n",
    "            text_inferenced = ocr_func(image_id_ground_truth, image_id)\n",
    "        else:\n",
    "            text_inferenced = ocr_func(image_id)\n",
    "        diff_dict = diff_all(text_ground_truth, text_inferenced)\n",
    "\n",
    "        # append results\n",
    "        row_data = [ocr_func.__name__, image_id]\n",
    "        for diff_name in diff_name_list:\n",
    "            diff_sum_dict[diff_name] = diff_sum_dict[diff_name] + diff_dict[diff_name]\n",
    "            row_data.append(diff_dict[diff_name])\n",
    "        diff_data_all.append(row_data)\n",
    "\n",
    "        # write inferenced text\n",
    "        ocr_output_folder = get_ocr_output_folder(ocr_func)\n",
    "        if ocr_output_folder:\n",
    "            with open(ocr_output_folder / Path(image_id + \".txt\"), \"w\") as f:\n",
    "                f.write(text_inferenced)\n",
    "\n",
    "    # append average\n",
    "    row_data = [ocr_func.__name__, \"average\"]\n",
    "    for diff_name in diff_name_list:\n",
    "        row_data.append(diff_sum_dict[diff_name] / len(image_id_list))\n",
    "    diff_data_all.append(row_data)\n",
    "\n",
    "df = pd.DataFrame(diff_data_all, columns=diff_data_columns)\n",
    "df.to_pickle(df_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc60413-540c-4605-a2f9-8e3e0c1fb3d9",
   "metadata": {},
   "source": [
    "## results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d8cdd9-cbdf-434e-b9d3-4d764a97460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(df_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fac9a39-7416-47ac-9c78-97967c37328d",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ae4b20-4c97-4696-b215-dbd3faae45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = df[df[\"image_id\"] == \"average\"].copy()\n",
    "function_labels = df_avg[\"function\"].unique()\n",
    "function_map = {name: i for i, name in enumerate(function_labels)}\n",
    "df_avg[\"function_code\"] = df_avg[\"function\"].map(function_map)\n",
    "metric_columns = [\"diff_levenshtein\", \"diff_wer\", \"diff_cer\", \"diff_difflib\"]\n",
    "dim_list = [{\"label\": col, \"values\": df_avg[col]} for col in metric_columns]\n",
    "dim_list.insert(\n",
    "    0,\n",
    "    {\n",
    "        \"label\": \"function\",\n",
    "        \"values\": df_avg[\"function_code\"],\n",
    "        \"tickvals\": list(function_map.values()),\n",
    "        \"ticktext\": list(function_map.keys()),\n",
    "    },\n",
    ")\n",
    "fig = go.Figure(\n",
    "    data=go.Parcoords(\n",
    "        line={\n",
    "            \"color\": list(df_avg.index),\n",
    "            \"colorscale\": \"Rainbow\",\n",
    "        },\n",
    "        dimensions=dim_list,\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    height=700,\n",
    "    font=dict(size=14),\n",
    "    margin=dict(l=200),\n",
    ")\n",
    "fig.write_html(plot_path)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
